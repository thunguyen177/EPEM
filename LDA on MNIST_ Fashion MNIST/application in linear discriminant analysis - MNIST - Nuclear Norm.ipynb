{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01Q1wGI3uIdg"
   },
   "source": [
    "## libraries and function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12437,
     "status": "ok",
     "timestamp": 1604108489411,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "iEdO9dJPION8",
    "outputId": "c151206d-c96c-4559-a491-9149ea9892a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: impyute in /usr/local/lib/python3.6/dist-packages (0.0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from impyute) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from impyute) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from impyute) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->impyute) (0.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install impyute\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import impyute as impy\n",
    "from fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Kk3Z0jcObqQ"
   },
   "source": [
    "### LDA and nan function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4-kNYKJIOOd"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "function that create data list that contain missing values\n",
    "The input X is a numpy array, y is the label\n",
    "the function return a list where the ith element of \n",
    "the list belongs to the ith class\n",
    "'''\n",
    "\n",
    "def make_nan_list(X,y,G, n, p):\n",
    "    # note that the label should go from 0 to G-1\n",
    "    data = []\n",
    "    for g in np.arange(G):\n",
    "        data.append(X[y==g,:])\n",
    "        for k in np.arange(len(p)-1):\n",
    "            data[g][n[g,k+1]:n[g,k], p[k]:] = np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwG2bsDOOxls"
   },
   "source": [
    "### compute_err function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oXh1_ou0BPS"
   },
   "outputs": [],
   "source": [
    "def missing_rate(Xtrain, ytrain, n, p, G):    \n",
    "    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n",
    "    # make NA data\n",
    "    # since making function changes the order of observation\n",
    "    # we need to generate new ytr from Xtr_nan    \n",
    "    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n",
    "    for g in np.arange(1,G):\n",
    "        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n",
    "        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n",
    "\n",
    "    # percentage of missing values\n",
    "    per_missing = np.mean(np.isnan(Xtr_nan))\n",
    "    return per_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKmRLxjIOCa6"
   },
   "outputs": [],
   "source": [
    "def compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, G):    \n",
    "    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n",
    "    # make NA data\n",
    "    # since making function changes the order of observation\n",
    "    # we need to generate new ytr from Xtr_nan    \n",
    "    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n",
    "    for g in np.arange(1,G):\n",
    "        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n",
    "        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n",
    "\n",
    "    # percentage of missing values\n",
    "    per_missing = np.mean(np.isnan(Xtr_nan))\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(Xtr_nan)\n",
    "    Xtr_nan = scaler.transform(Xtr_nan)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    Xtr_nan_list2 = []\n",
    "    for g in range(G):\n",
    "      Xtr_nan_list2.append(scaler.transform(Xtr_nan_list[g]))\n",
    "    \n",
    "    #impute,classify and get the error rates for imputation approaches    \n",
    "    start = time.time()\n",
    "    Xtr_nuclear = NuclearNormMinimization(max_iters=10).fit_transform(Xtr_nan)\n",
    "    clf_nuclear = skLDA().fit(Xtr_nuclear, ytr)\n",
    "    nuclear_err = np.mean(clf_nuclear.predict(Xtest).flatten() != ytest)\n",
    "    nuclear_time = time.time()-start\n",
    " \n",
    "    return nuclear_err, nuclear_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AguK8ubkws4v"
   },
   "source": [
    "## Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPTl_fTnwviG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Fetch the dataset directly\n",
    "mnist = tfds.image.MNIST()\n",
    "# or by string name\n",
    "mnist = tfds.builder('mnist')\n",
    "\n",
    "# Download the data, prepare it, and write it to disk\n",
    "mnist.download_and_prepare()\n",
    "\n",
    "# Load data from disk as tf.data.Datasets\n",
    "datasets = mnist.as_dataset()\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19251,
     "status": "ok",
     "timestamp": 1604108542039,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "s1SDGIx5zDYc",
    "outputId": "6cef3b0d-79a7-423e-bf21-14dadeeb9d45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the Dataset to NumPy arrays and flatten the data\n",
    "Xtrain_np, ytrain_np = [], []\n",
    "for example in tfds.as_numpy(train_dataset):\n",
    "  Xtrain_np.append(example['image'].flatten())\n",
    "  ytrain_np.append(example['label'])\n",
    "\n",
    "\n",
    "Xtrain, ytrain = np.asarray(Xtrain_np), np.asarray(ytrain_np)\n",
    "Xtrain = Xtrain.astype(float)\n",
    "\n",
    "# set random seed and shuffle the data\n",
    "np.random.seed(1)\n",
    "idx = np.arange(len(ytrain))\n",
    "np.random.shuffle(idx)\n",
    "Xtrain, ytrain = Xtrain[idx,:], ytrain[idx]  \n",
    "\n",
    "Xtrain.shape, ytrain.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDzlDpqu6k3C"
   },
   "outputs": [],
   "source": [
    "# convert the test set to NumPy arrays and flatten the data\n",
    "Xtest, ytest = [], []\n",
    "for example in tfds.as_numpy(test_dataset):\n",
    "  Xtest.append(example['image'].flatten())\n",
    "  ytest.append(example['label'])\n",
    "\n",
    "Xtest, ytest = np.asarray(Xtest), np.asarray(ytest)\n",
    "Xtest = Xtest.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15315,
     "status": "ok",
     "timestamp": 1604108544535,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "mnuVedleA4U-",
    "outputId": "8ecbd9a7-3854-49d1-8b22-9a18c2a212c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "649"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a column is all 0\n",
    "id = [np.sum(Xtrain[:,i] != 0)>10 for i in range(28**2)]\n",
    "# number of columns that mostly zero\n",
    "print(28**2-np.sum(id))\n",
    "# number of columns that has at least more than 10 non-zero\n",
    "np.sum(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8WD9y-kDCBC"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest = Xtrain[:,id], Xtest[:,id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12097,
     "status": "ok",
     "timestamp": 1604108545433,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "ALB2IHmhDnoh",
    "outputId": "d797f484-2915-4701-c57d-3d06aa2df0ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 649), (10000, 649))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJz_5pzCKHhp"
   },
   "outputs": [],
   "source": [
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3omLMDgKNVp"
   },
   "outputs": [],
   "source": [
    "del test_dataset\n",
    "del Xtrain_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2628,
     "status": "ok",
     "timestamp": 1604108563397,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "AQvbp-Hy2-dB",
    "outputId": "0f6f3d93-2850-48e6-f985-9e38a6e2debb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sample per class in training data\n",
    "ng = np.asarray([sum(ytrain==i) for i in np.arange(10)])\n",
    "ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY0XX7TS1p_6"
   },
   "source": [
    "## 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2982,
     "status": "ok",
     "timestamp": 1604106998725,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "5qBxF28a26Ub",
    "outputId": "a08c4f05-abca-4e23-f229-e10a76fc6cb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19940934771443247"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.hstack((ng.reshape((-1,1)), np.tile([4500,4200,3700, 3500],\n",
    "                                 10).reshape((10,-1))))\n",
    "p = np.array([300,320,400, 500,649])   \n",
    "missing_rate(Xtrain, ytrain, n, p, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUEC8kdJOiAK"
   },
   "outputs": [],
   "source": [
    "nuc20 = compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, 10)\n",
    "nuc20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5v8ssVSPfXY"
   },
   "source": [
    "## 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2129,
     "status": "ok",
     "timestamp": 1604107261740,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "PUe2msZgPkcK",
    "outputId": "70cd0129-4434-4bb0-e7db-5402f69f7392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2997945557267591"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.hstack((ng.reshape((-1,1)), np.tile([4500,4200,3700, 3400],\n",
    "                                 10).reshape((10,-1))))\n",
    "p = np.array([100,250,350, 400,649])   \n",
    "missing_rate(Xtrain, ytrain, n, p, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6-cz45APgV4"
   },
   "outputs": [],
   "source": [
    "nuc30 = compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, 10)\n",
    "nuc30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcN5qrjMUGSq"
   },
   "source": [
    "## 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1604108652943,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": 300
    },
    "id": "IhEelW8WPmtd",
    "outputId": "5d4c92d9-c0c3-4311-aefc-9be65391a353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39717514124293785"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.hstack((ng.reshape((-1,1)), np.tile([4000,3500,3000, 2600],\n",
    "                                 10).reshape((10,-1))))\n",
    "p = np.array([100,250,350, 400,649])   \n",
    "missing_rate(Xtrain, ytrain, n, p, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FE1DHCYUM3Z"
   },
   "outputs": [],
   "source": [
    "nuc40 = compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, 10)\n",
    "nuc40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Tz-jJw3U-M4"
   },
   "outputs": [],
   "source": [
    "np.vstack((nuc20, nuc30, nuc40))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "application in linear discriminant analysis - MNIST - Nuclear Norm.ipynb",
   "provenance": [
    {
     "file_id": "1sjnSefUvqeuO5agsAWfuOR_wJTjTfNvN",
     "timestamp": 1603783755716
    },
    {
     "file_id": "1arXCMY131I_hMzl3EnfSKESUQmwIHoZM",
     "timestamp": 1603783037611
    },
    {
     "file_id": "1UPCB9FT9px24oZYoQRXSsOmvBFbAACF3",
     "timestamp": 1603782625541
    },
    {
     "file_id": "1tR40bOS9ThPI2uK0uthQ8LnWLmmQaDr8",
     "timestamp": 1603678172225
    },
    {
     "file_id": "1CnbOqwmJydQa8uCCpIR6HRVxw0YnveIP",
     "timestamp": 1591365193693
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
